---
layout: page
title: General to Particular (G2P) algorithm
---
# Companion Website
<img src="../../img/nmi_banner.jpg">

## Nature Machine Intelligence - March 2019

# [Article (open-access): Nature.com](https://www.nature.com/articles/s42256-019-0029-0)
# [Arxiv Preprint](https://arxiv.org/pdf/1810.08615.pdf)
A tendon-driven robotic limb learns movements autonomously from sparse experience, by a short period of ‘motor babbling’ (that is, repeated exploratory movements), followed by a phase of reinforcement learning. In the photo, the limb is learning to make cyclic movements to propel the treadmill. The approach is a step towards designing robots with the versatility and robustness of vertebrates, which can adapt quickly to everyday environments.




### **Abstract:**
Robots will become ubiquitously useful only when they require just a few attempts to teach themselves to perform different tasks, even with complex bodies and in dynamic environments. Vertebrates use sparse trial and error to learn multiple tasks, despite their intricate tendon-driven anatomies, which are particularly hard to control because they are simultaneously nonlinear, under-determined and over-determined. We demonstrate—in simulation and hardware—how a model-free, open-loop approach allows few-shot autonomous learning to produce effective movements in a three-tendon two-joint limb. We use a short period of motor babbling (to create an initial inverse map) followed by building functional habits by reinforcing high-reward behaviour and refinements of the inverse map in a movement’s neighbourhood. This biologically plausible algorithm, which we call G2P (general to particular), can potentially enable quick, robust and versatile adaptation in robots as well as shed light on the foundations of the enviable functional versatility of organisms.

### Funding
Research reported in this publication was supported in part by the National Institute of Arthritis and Musculoskeletal and Skin Diseases of the National Institutes of Health under award numbers R01 AR-050520, R01 AR-052345, the Department of Defense CDMRP Grant MR150091, and Award W911NF1820264 from the DARPA's Lifelong Learning Machines (L2M) program.

### Have comments or questions about how to apply these methods to your work?
We'd be happy to help. Send us a message: [marjanin@usc.edu](mailto:marjanin@usc.edu)
[Machine Learning Code: marjanin/Marjaninejad-et-al-2019-NMI](https://github.com/marjanin/Marjaninejad-et.-al.-2019-NMI)

### In press

[Nature: Editorial](https://doi.org/10.1038/s42256-019-0035-2)

[Defense Advanced Research Projects Agency (DARPA)](https://www.darpa.mil/news-events/2019-03-12)

[Longroom](https://longroom.com/discussion/1401781/a-robotic-leg-born-without-prior-knowledge-learns-to-walk)

[Nanowerk](https://www.nanowerk.com/news2/robotics/newsid=52337.php)

[TechXplore: Robotics](https://techxplore.com/news/2019-03-robotic-leg-born-prior-knowledge.html)

[Neuroscience News](https://neurosciencenews.com/ai-robotic-leg-learns-walk-10878/)

[USC Viterbi School of Engineering](https://viterbischool.usc.edu/news/2019/03/a-robotic-leg-born-without-prior-knowledge-learns-to-walk/)

[PCMag](https://www.pcmag.com/news/367051/how-this-robotic-leg-learned-to-walk-by-itself)

[EurekAlert-AAAS Photo](https://www.eurekalert.org/multimedia/pub/195144.php)

[EurekAlert-AAAS Article](https://www.eurekalert.org/pub_releases/2019-03/uosc-arl031019.php)

[TuniseSoir News](http://www.tunisiesoir.com/science/research-new-ai-algorithms-could-allow-robots-to-learn-to-move-by-themselves-imitating-animals-13989-2019/)

[ScienceDaily](https://www.sciencedaily.com/releases/2019/03/190311125138.htm)

[NeuroLogica Blog](https://theness.com/neurologicablog/index.php/robots-learning-to-walk/)


*Supplemental site prepared by: Brian A. Cohn and Ali Marjaninejad*
